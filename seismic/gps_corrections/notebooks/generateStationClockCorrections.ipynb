{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze a cross-correlation to produce station clock correction file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior to using this script, the quality of the correction should be visualized and confirmed using notebook `plotStationPairXcorr.ipynb`\n",
    "\n",
    "This notebook will generate a csv file with dates and estimated clock corrections for a given station. Applying the correction to the original ASDF database will be done separately for the sake of safety, so that any changes to ASDF must be very deliberate and intentional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.dates\n",
    "import matplotlib.pyplot as plt\n",
    "from dateutil import rrule\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import obspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "package_root = os.path.abspath('../../..')\n",
    "if package_root not in sys.path:\n",
    "    sys.path.append(package_root)\n",
    "from seismic.xcorqc.xcorr_station_clock_analysis import (XcorrPreprocessor, \n",
    "                                                         compute_estimated_clock_corrections,\n",
    "                                                         plot_estimated_timeshift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SRC_FILE = \"/g/data/ha3/am7399/shared/xcorr/7X/MA43_QIS/7X.MA43.AU.QIS.1.0-10.0.nc\"\n",
    "SRC_FILE = \"/g/data/ha3/am7399/shared/xcorr/7X/MA52_QIS/7X.MA52.AU.QIS.1.0-10.0.nc\"\n",
    "assert os.path.exists(SRC_FILE), \"File not found!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, basename = os.path.split(SRC_FILE)\n",
    "name_parts = basename.split('.')\n",
    "NETCODE = name_parts[0]\n",
    "STATCODE = name_parts[1]\n",
    "print(\"Inferred target station code: {}.{}\".format(NETCODE, STATCODE))\n",
    "FULL_CODE = '.'.join([NETCODE, STATCODE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_WINDOW = 300 # +/-\n",
    "SNR_THRESHOLD = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xcorr_preproc = XcorrPreprocessor(SRC_FILE, TIME_WINDOW, SNR_THRESHOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCF_CUTOFF_THRESHOLD = 0.5\n",
    "rcf_corrected, correction, row_rcf_crosscorr = \\\n",
    "    compute_estimated_clock_corrections(xcorr_preproc.rcf, xcorr_preproc.snr_mask,\n",
    "                                        xcorr_preproc.ccf_masked, xcorr_preproc.lag,\n",
    "                                        PCF_CUTOFF_THRESHOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data for visual check\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.subplot(1, 2, 1)\n",
    "ax = plt.gca()\n",
    "plot_estimated_timeshift(ax, xcorr_preproc.lag, xcorr_preproc.start_times, correction)\n",
    "date_formatter = matplotlib.dates.DateFormatter(\"%Y-%m-%d\")\n",
    "date_locator = matplotlib.dates.WeekdayLocator(byweekday=rrule.SU)\n",
    "ax.yaxis.set_major_formatter(date_formatter)\n",
    "ax.yaxis.set_major_locator(date_locator)\n",
    "ytl = ax.get_yticklabels()\n",
    "for _ytl in ytl:\n",
    "    _ytl.set_visible(True)\n",
    "ax.set_ylabel('Days')\n",
    "ax.set_title('Computed clock corrections')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "ax = plt.gca()\n",
    "plot_estimated_timeshift(ax, xcorr_preproc.lag, xcorr_preproc.start_times, correction, \n",
    "                         row_rcf_crosscorr=row_rcf_crosscorr)\n",
    "ax.yaxis.set_major_formatter(date_formatter)\n",
    "ax.yaxis.set_major_locator(date_locator)\n",
    "ax.set_title('RCF * CCF used for corrections')\n",
    "\n",
    "plt.suptitle('GPS Clock Corrections for {}'.format(xcorr_preproc.src_file), fontsize=16, y=0.92)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment the corrections time series into coherent groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flt_times = np.array([float(v) for v in xcorr_preproc.start_times])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import dbscan\n",
    "from scipy import signal\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_per_week = 7*24*3600\n",
    "\n",
    "tuned_coeffs = {\n",
    "    '7X.MA43': (1, 1, 20),\n",
    "    '7X.MA52': (1, 5, 15)\n",
    "}\n",
    "\n",
    "\n",
    "def temporalDist2D(p0, p1):\n",
    "    return math.sqrt((tuned_coeffs[FULL_CODE][0] * (p1[0] - p0[0]))**2 +\n",
    "                     (tuned_coeffs[FULL_CODE][1] * sec_per_week*(p1[1] - p0[1]))**2)\n",
    "\n",
    "def calendarDist(p0, p1):\n",
    "    return abs(p1[0] - p0[0])\n",
    "\n",
    "\n",
    "assert not np.any(np.isnan(flt_times))\n",
    "nan_mask = np.isnan(correction)\n",
    "times_nonan = flt_times[~nan_mask]\n",
    "correction_nonan = correction[~nan_mask]\n",
    "data = np.column_stack((times_nonan, correction_nonan))\n",
    "\n",
    "ind, ids = dbscan(data, eps=2*sec_per_week, min_samples=7, metric=temporalDist2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_times = np.array([datetime.datetime.utcfromtimestamp(v) for v in xcorr_preproc.start_times]).astype('datetime64[ms]')\n",
    "np_times = np_times[~nan_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot clusters based on sample positions in time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,9))\n",
    "\n",
    "plt.plot(np_times, correction_nonan, 'x', color=\"#808080\")\n",
    "for i in range(max(ids) + 1):\n",
    "    mask_group = (ids == i)\n",
    "    plt.plot(np_times[mask_group], correction_nonan[mask_group], 'o-', color='C{}'.format(i),\n",
    "             markersize=6, fillstyle='none', alpha=0.7)\n",
    "\n",
    "time_formatter = matplotlib.dates.DateFormatter(\"%Y-%m-%d\")\n",
    "plt.axes().xaxis.set_major_formatter(time_formatter)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.grid(':', color=\"#808080\", zorder=0, alpha=0.5)\n",
    "plt.xlabel('Day', fontsize=14)\n",
    "plt.ylabel('Correction (sec)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.title(\"Station {} zeroth order corrections groups\".format(FULL_CODE), fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note how ignoring the slope results in last group not being split into two. Next we add the slope to the distance metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add slope metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = np.gradient(correction_nonan, times_nonan, edge_order=1)\n",
    "grad_med5 = signal.medfilt(grad, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope = grad_med5\n",
    "\n",
    "def temporalDist2DSlope(p0, p1):\n",
    "    return math.sqrt((tuned_coeffs[FULL_CODE][0] * (p1[0] - p0[0]))**2 + \n",
    "                     (tuned_coeffs[FULL_CODE][1] * sec_per_week*(p1[1] - p0[1]))**2 +\n",
    "                     (tuned_coeffs[FULL_CODE][2] * sec_per_week*sec_per_week*(p1[2] - p0[2]))**2)\n",
    "\n",
    "assert not np.any(np.isnan(flt_times))\n",
    "data = np.column_stack((times_nonan, correction_nonan, slope))\n",
    "# print(data)\n",
    "\n",
    "ind2, ids2 = dbscan(data, eps=2*sec_per_week, min_samples=7, metric=temporalDist2DSlope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,9))\n",
    "\n",
    "plt.plot(np_times, correction_nonan, 'x', color=\"#808080\")\n",
    "for i in range(max(ids2) + 1):\n",
    "    mask_group = (ids2 == i)\n",
    "    plt.plot(np_times[mask_group], correction_nonan[mask_group], 'o-', color='C{}'.format(i),\n",
    "             markersize=5, fillstyle='none')\n",
    "\n",
    "time_formatter = matplotlib.dates.DateFormatter(\"%Y-%m-%d\")\n",
    "ylims = plt.ylim()\n",
    "plt.axes().xaxis.set_major_formatter(time_formatter)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.grid(':', color=\"#808080\", zorder=0, alpha=0.5)\n",
    "plt.xlabel('Day', fontsize=14)\n",
    "plt.ylabel('Correction (sec)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.title(\"Station {} first order corrections groups\".format(FULL_CODE), fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With successful segmentation, we perform regression for each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(times_nonan), len(np_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_segments = len(set(ids2[ids2 != -1]))\n",
    "print(num_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict of regressions, keyed by group ID\n",
    "regressions = {}\n",
    "\n",
    "# Corrections from regression function fit\n",
    "correction_fit = np.zeros_like(correction_nonan)\n",
    "correction_fit[:] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_segments):\n",
    "    mask_group = (ids2 == i)\n",
    "    # Perform regression\n",
    "    x = times_nonan[mask_group]\n",
    "    y = correction_nonan[mask_group]\n",
    "    r = np.polyfit(x, y, 1)\n",
    "    regressions[i] = r\n",
    "    # Compute fitted values\n",
    "    correction_fit[mask_group] = np.polyval(r, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replot with fitted line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,9))\n",
    "\n",
    "# plt.plot(np_times, correction_nonan, 'x', color=\"#808080\")\n",
    "for i in range(num_segments):\n",
    "    mask_group = (ids2 == i)\n",
    "    plt.plot(np_times[mask_group], correction_nonan[mask_group], 'o', color='C{}'.format(i),\n",
    "             markersize=5, fillstyle='none')\n",
    "    plt.plot(np_times[mask_group], correction_fit[mask_group], color='C{}'.format(i))\n",
    "\n",
    "time_formatter = matplotlib.dates.DateFormatter(\"%Y-%m-%d\")\n",
    "plt.axes().xaxis.set_major_formatter(time_formatter)\n",
    "plt.ylim(ylims)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.grid(':', color=\"#808080\", zorder=0, alpha=0.5)\n",
    "plt.xlabel('Day', fontsize=14)\n",
    "plt.ylabel('Correction (sec)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.title(\"Station {} corrections groups with regressions to sample times\".format(FULL_CODE), fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict of daily spaced time values and computed correction, since source data time\n",
    "# points might not be uniformly distributed. Keyed by group ID. These are the times\n",
    "# at which we will output corrections.\n",
    "regular_corrections = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_per_day = 24*3600\n",
    "\n",
    "for i in range(num_segments):\n",
    "    mask_group = (ids2 == i)\n",
    "    # Generate uniform daily times at which to compute corrections\n",
    "    x = times_nonan[mask_group]\n",
    "    timestamp_min = min(x)\n",
    "    timestamp_max = max(x)\n",
    "    num_days = np.round((timestamp_max - timestamp_min)/sec_per_day)\n",
    "    lin_times = np.linspace(timestamp_min, timestamp_max, num_days + 1)\n",
    "    lin_corrections = np.polyval(regressions[i], lin_times)\n",
    "    regular_corrections[i] = {'times': lin_times, 'corrections': lin_corrections}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replot to sanity check the final daily correction values\n",
    "plt.figure(figsize=(16,9))\n",
    "\n",
    "# plt.plot(np_times, correction_nonan, 'x', color=\"#808080\")\n",
    "for i in range(num_segments):\n",
    "    mask_group = (ids2 == i)\n",
    "    plt.plot(np_times[mask_group], correction_nonan[mask_group], 'o', color='#808080'.format(i),\n",
    "             markersize=5, fillstyle='none')\n",
    "    np_times_i = np.array([datetime.datetime.utcfromtimestamp(v) for v in \n",
    "                           regular_corrections[i]['times']]).astype('datetime64[ms]')\n",
    "    plt.plot(np_times_i, regular_corrections[i]['corrections'], 'o', color='C{}'.format(i), fillstyle='none')\n",
    "\n",
    "time_formatter = matplotlib.dates.DateFormatter(\"%Y-%m-%d\")\n",
    "plt.axes().xaxis.set_major_formatter(time_formatter)\n",
    "plt.ylim(ylims)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.grid(':', color=\"#808080\", zorder=0, alpha=0.5)\n",
    "plt.xlabel('Day', fontsize=14)\n",
    "plt.ylabel('Correction (sec)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.title(\"Station {} corrections groups with regressions to daily samples\".format(FULL_CODE), fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output regression results to csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use tabular format for ease of use and interoperability, even though there will be some redundancy of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_blocks = []\n",
    "for k in regular_corrections.keys():\n",
    "    c = regular_corrections[k]\n",
    "    # BEWARE: The 'corrections' array sign is negated there, since the correction\n",
    "    # we have computed up to this point is actually the clock *error*. Subtraction\n",
    "    # of an error is the same as addition of a correction of opposite sign.\n",
    "    data_blocks.append(pd.DataFrame(np.column_stack([c['times'], -c['corrections']]), \n",
    "                                    columns=['timestamp', 'clock_correction']))\n",
    "df = pd.concat(data_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = df['timestamp'].apply(obspy.UTCDateTime).apply(lambda x: x.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['net'] = NETCODE\n",
    "df['sta'] = STATCODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['net', 'sta', 'date', 'clock_correction']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = FULL_CODE + \"_clock_correction.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
